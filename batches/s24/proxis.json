{
  "id": 29668,
  "name": "Proxis",
  "slug": "proxis",
  "former_names": [],
  "small_logo_thumb_url": "https://bookface-images.s3.amazonaws.com/small_logos/58c309e9f0667689e728737a8880efae9b16e7d6.png",
  "website": "https://www.proxis.ai/",
  "all_locations": "San Francisco, CA, USA",
  "long_description": "We bring the same technology optimizations that power ChatGPT and Gemini for low-cost inferences to Llama models with an easy to use API. \r\n\r\nWith one line of code change, developers can cut inference costs by up to 50% while still matching Llama 405b quality on complex queries. We achieve this through hardware specific kernel-level optimizations, combined with cascaded serving to dynamically run inferences on the most appropriate model architecture. \r\n\r\nWhile we work on ensuring API reliability and uptime, join our waitlist at proxis.ai.",
  "one_liner": "The cheapest API for serving Llama models.",
  "team_size": 2,
  "highlight_black": false,
  "highlight_latinx": false,
  "highlight_women": false,
  "industry": "B2B",
  "subindustry": "Unspecified",
  "launched_at": 1725054386,
  "tags": [
    "Artificial Intelligence",
    "Generative AI",
    "Cloud Computing",
    "AI"
  ],
  "tags_highlighted": [],
  "top_company": false,
  "isHiring": false,
  "nonprofit": false,
  "batch": "S24",
  "status": "Active",
  "industries": [
    "B2B",
    "Engineering, Product and Design"
  ],
  "regions": [
    "United States of America",
    "America / Canada"
  ],
  "stage": "Early",
  "app_video_public": false,
  "demo_day_video_public": false,
  "app_answers": null,
  "question_answers": false,
  "url": "https://www.ycombinator.com/companies/proxis",
  "api": "https://yc-oss.github.io/api/batches/s24/proxis.json"
}
